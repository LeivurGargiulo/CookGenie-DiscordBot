#!/usr/bin/env python3
"""
Utility script to switch between LLM providers for Recipe Genie bot
"""

import os
import sys
from pathlib import Path

def read_env_file(env_path):
    """Read .env file and return as dictionary."""
    if not env_path.exists():
        return {}
    
    env_vars = {}
    with open(env_path, 'r') as f:
        for line in f:
            line = line.strip()
            if line and not line.startswith('#') and '=' in line:
                key, value = line.split('=', 1)
                env_vars[key] = value
    return env_vars

def write_env_file(env_path, env_vars):
    """Write dictionary to .env file."""
    with open(env_path, 'w') as f:
        f.write("# Recipe Genie Bot Configuration\n")
        f.write("# Generated by switch_provider.py\n\n")
        
        for key, value in env_vars.items():
            f.write(f"{key}={value}\n")

def switch_to_openrouter():
    """Switch configuration to OpenRouter."""
    env_path = Path('.env')
    env_vars = read_env_file(env_path)
    
    print("üîß Switching to OpenRouter...")
    
    # Update provider
    env_vars['LLM_PROVIDER'] = 'openrouter'
    
    # Ensure OpenRouter settings exist
    if 'OPENROUTER_API_KEY' not in env_vars:
        env_vars['OPENROUTER_API_KEY'] = 'your_openrouter_api_key_here'
    if 'OPENROUTER_MODEL' not in env_vars:
        env_vars['OPENROUTER_MODEL'] = 'anthropic/claude-3-haiku'
    if 'OPENROUTER_ENDPOINT' not in env_vars:
        env_vars['OPENROUTER_ENDPOINT'] = 'https://openrouter.ai/api/v1/chat/completions'
    if 'OPENROUTER_TIMEOUT' not in env_vars:
        env_vars['OPENROUTER_TIMEOUT'] = '30'
    if 'OPENROUTER_MAX_TOKENS' not in env_vars:
        env_vars['OPENROUTER_MAX_TOKENS'] = '500'
    if 'OPENROUTER_TEMPERATURE' not in env_vars:
        env_vars['OPENROUTER_TEMPERATURE'] = '0.7'
    
    write_env_file(env_path, env_vars)
    
    print("‚úÖ Switched to OpenRouter!")
    print("\nüìù Next steps:")
    print("1. Edit .env file and set your OPENROUTER_API_KEY")
    print("2. Optionally change OPENROUTER_MODEL to your preferred model")
    print("3. Test with: python test_llm_integration.py")
    print("4. Run bot with: python recipe_genie_bot_openrouter.py")

def switch_to_local():
    """Switch configuration to local LLM."""
    env_path = Path('.env')
    env_vars = read_env_file(env_path)
    
    print("üîß Switching to Local LLM...")
    
    # Update provider
    env_vars['LLM_PROVIDER'] = 'local'
    
    # Ensure local LLM settings exist
    if 'LLM_ENDPOINT' not in env_vars:
        env_vars['LLM_ENDPOINT'] = 'http://localhost:1234/v1/chat/completions'
    if 'LLM_MODEL' not in env_vars:
        env_vars['LLM_MODEL'] = 'your_model_name_here'
    if 'LLM_API_KEY' not in env_vars:
        env_vars['LLM_API_KEY'] = ''
    if 'LLM_TIMEOUT' not in env_vars:
        env_vars['LLM_TIMEOUT'] = '30'
    if 'LLM_MAX_TOKENS' not in env_vars:
        env_vars['LLM_MAX_TOKENS'] = '500'
    if 'LLM_TEMPERATURE' not in env_vars:
        env_vars['LLM_TEMPERATURE'] = '0.7'
    
    write_env_file(env_path, env_vars)
    
    print("‚úÖ Switched to Local LLM!")
    print("\nüìù Next steps:")
    print("1. Start your local LLM server (e.g., LMStudio)")
    print("2. Edit .env file and set your LLM_MODEL")
    print("3. Test with: python test_llm_integration.py")
    print("4. Run bot with: python recipe_genie_bot_enhanced.py")

def show_current_config():
    """Show current configuration."""
    env_path = Path('.env')
    if not env_path.exists():
        print("‚ùå No .env file found!")
        return
    
    env_vars = read_env_file(env_path)
    provider = env_vars.get('LLM_PROVIDER', 'not set')
    
    print(f"üîß Current Provider: {provider}")
    
    if provider == 'openrouter':
        model = env_vars.get('OPENROUTER_MODEL', 'not set')
        api_key = env_vars.get('OPENROUTER_API_KEY', 'not set')
        print(f"üìã Model: {model}")
        print(f"üîë API Key: {'‚úÖ Set' if api_key != 'your_openrouter_api_key_here' and api_key else '‚ùå Not set'}")
    elif provider == 'local':
        model = env_vars.get('LLM_MODEL', 'not set')
        endpoint = env_vars.get('LLM_ENDPOINT', 'not set')
        print(f"üìã Model: {model}")
        print(f"üåê Endpoint: {endpoint}")
    else:
        print("‚ùå Invalid or missing provider configuration")

def main():
    """Main function."""
    print("üç≥ Recipe Genie - LLM Provider Switcher")
    print("=" * 40)
    
    if len(sys.argv) < 2:
        print("Usage:")
        print("  python switch_provider.py openrouter  # Switch to OpenRouter")
        print("  python switch_provider.py local       # Switch to Local LLM")
        print("  python switch_provider.py status      # Show current config")
        return
    
    command = sys.argv[1].lower()
    
    if command == 'openrouter':
        switch_to_openrouter()
    elif command == 'local':
        switch_to_local()
    elif command == 'status':
        show_current_config()
    else:
        print(f"‚ùå Unknown command: {command}")
        print("Available commands: openrouter, local, status")

if __name__ == "__main__":
    main()